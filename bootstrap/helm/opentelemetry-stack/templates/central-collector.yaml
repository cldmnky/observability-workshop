apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: {{ .Values.centralCollector.name }}
  namespace: {{ .Values.namespace }}
  annotations:
    argocd.argoproj.io/sync-wave: "3"
    argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
spec:
  # Deployment mode with multiple replicas
  mode: deployment
  replicas: {{ .Values.centralCollector.replicas }}
  
  # Service account with Tempo write permissions
  serviceAccount: {{ .Values.serviceAccounts.central }}
  
  # OpenTelemetry Collector configuration
  config:
    # Extensions
    extensions:
      # Bearer token authentication for Tempo
      bearertokenauth:
        filename: /var/run/secrets/kubernetes.io/serviceaccount/token
    
    # Receivers - accept telemetry from sidecar collectors
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
    
    {{- if .Values.centralCollector.spanmetrics.enabled }}
    # Connectors - generate metrics from traces
    connectors:
      spanmetrics:
        # Histogram buckets for latency metrics
        histogram:
          explicit:
            buckets:
              {{- range .Values.centralCollector.spanmetrics.histogramBuckets }}
              - {{ . }}
              {{- end }}
        # Dimensions to extract from spans
        dimensions:
          {{- range .Values.centralCollector.spanmetrics.dimensions }}
          - name: {{ .name }}
          {{- end }}
        # Enable exemplars for trace-metric correlation
        exemplars:
          enabled: {{ .Values.centralCollector.spanmetrics.exemplarsEnabled }}
        # Metrics flush interval
        metrics_flush_interval: {{ .Values.centralCollector.spanmetrics.flushInterval }}
    {{- end }}
    
    # Processors - enrich and transform telemetry
    processors:
      # Memory limiter to prevent OOM
      memory_limiter:
        check_interval: 1s
        limit_mib: {{ .Values.centralCollector.memoryLimit }}
        spike_limit_mib: 200
      
      # Resource detection - OpenShift metadata
      resourcedetection:
        detectors:
        - openshift
        timeout: 2s
      
      # Kubernetes attributes - pod, namespace, etc.
      k8sattributes:
        auth_type: serviceAccount
        passthrough: false
        extract:
          metadata:
          - k8s.namespace.name
          - k8s.deployment.name
          - k8s.statefulset.name
          - k8s.daemonset.name
          - k8s.cronjob.name
          - k8s.job.name
          - k8s.node.name
          - k8s.pod.name
          - k8s.pod.uid
          - k8s.pod.start_time
      
      {{- if .Values.centralCollector.spanmetrics.enabled }}
      # Rename spanmetrics output metrics using OTTL transform processor
      transform:
        metric_statements:
          - context: metric
            statements:
              - set(name, "traces_spanmetrics_calls_total") where name == "calls_total"
              - set(name, "traces_spanmetrics_latency") where name == "latency"
      {{- end }}
      
      # Map OTEL resource attributes to Loki label keys expected by openshift-logging tenancy mode
      resource/logs:
        attributes:
          - key: kubernetes.namespace_name
            from_attribute: k8s.namespace.name
            action: upsert
          - key: kubernetes.pod_name
            from_attribute: k8s.pod.name
            action: upsert
          - key: kubernetes.container_name
            from_attribute: k8s.container.name
            action: upsert
          - key: log_type
            value: application
            action: upsert
      
      # Derive a 'level' log attribute from the OTEL severity_text field
      transform/logs:
        log_statements:
          - context: log
            statements:
              - set(attributes["level"], ConvertCase(severity_text, "lower")) where severity_text != ""
      
      # Batch processor for efficiency
      batch:
        timeout: 10s
        send_batch_size: 1024
    
    # Exporters - send telemetry to backends
    exporters:
      # Tempo exporter for traces (otlp_grpc replaces deprecated otlp alias)
      # TLS required by Tempo distributor; skip verify (cert-manager cert, not service-ca)
      # No bearertokenauth - distributor does not require auth; X-Scope-OrgID header sets tenant
      otlp_grpc/tempo:
        endpoint: {{ .Values.centralCollector.tempo.endpoint }}
        tls:
          insecure_skip_verify: true
        headers:
          X-Scope-OrgID: {{ .Values.centralCollector.tempo.tenant }}
      
      # Prometheus remote write for metrics
      prometheusremotewrite:
        endpoint: {{ .Values.centralCollector.prometheus.endpoint }}
        resource_to_telemetry_conversion:
          enabled: true
      
      # LokiStack OTLP/HTTP log forwarder (otlp_http replaces deprecated otlphttp alias)
      otlp_http/logs:
        endpoint: {{ .Values.centralCollector.loki.endpoint }}
        encoding: json
        tls:
          ca_file: {{ .Values.centralCollector.loki.caFile }}
        auth:
          authenticator: bearertokenauth
      
      # Debug exporter for troubleshooting
      debug:
        verbosity: basic
    
    # Service configuration
    service:
      # Extensions
      extensions:
      - bearertokenauth
      
      # Pipelines
      pipelines:
        # Traces pipeline - send to Tempo and spanmetrics connector
        traces:
          receivers:
          - otlp
          processors:
          - memory_limiter
          - resourcedetection
          - k8sattributes
          - batch
          exporters:
          - otlp_grpc/tempo
          {{- if .Values.centralCollector.spanmetrics.enabled }}
          - spanmetrics
          {{- end }}
        
        {{- if .Values.centralCollector.spanmetrics.enabled }}
        # Spanmetrics pipeline - RED metrics generated from traces by the spanmetrics connector
        # Must be a metrics pipeline: spanmetrics connector produces metrics, not traces
        metrics/spanmetrics:
          receivers:
          - spanmetrics
          processors:
          - transform
          - batch
          exporters:
          - prometheusremotewrite
        {{- end }}
        
        # Metrics pipeline - send to Prometheus
        metrics:
          receivers:
          - otlp
          processors:
          - memory_limiter
          - resourcedetection
          - k8sattributes
          - batch
          exporters:
          - prometheusremotewrite
        
        # Logs pipeline - forward to LokiStack
        logs:
          receivers:
          - otlp
          processors:
          - memory_limiter
          - resourcedetection
          - k8sattributes
          - resource/logs
          - transform/logs
          - batch
          exporters:
          - otlp_http/logs
          - debug
